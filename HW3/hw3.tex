\documentclass[10pt]{article}

\usepackage{enumerate}
\usepackage{amsmath}
\usepackage[top=1in, bottom=1in, left=1in, right=1in]{geometry}

\title{600.465 -- Natural Language Processing\\
Assignment 2: Probability and Vector Exercises}
\author{}
\date{February 2016}

\begin{document}

\maketitle
\begin{enumerate}
    \item  % problem 1
    Sample 1:\\ $log_2$probability: $-12111.3$, word count: $1686$, perplexity per word: $2^{-12111.3/1686} = 0.00688$\\
    Sample 2:\\ $log_2$probability: $-7388.84$, word count: $978$, perplexity per word: $2^{-7388.84/978} = 0.00532$\\
    Sample 3:\\ $log_2$probability: $-7468.29$, word count: $985$, perplexity per word: $2^{-7468.29/985} = 0.00522$\\
    
    When switch to the larger {\tt switchboard} corpus the $log_2$probabilities went slightly lower together with the perplexities. This is because typically larger corpus have more words than smaller ones, making the probabilities of words in the sample lower. 
    
    
    \item % problem 2
    
    
\end{enumerate}

\end{document}
