Team member:
Jinyi Guo
Li-Yi Lin


1.
    (a)
    i. The new probability of day 1 is hot is 0.491 (the old probability is 0.871).


        p(133 | HHH) = p(1 | H) * p(3 | H) * p(3 | H) = 0.049
        p(133 | CHH) = p(1 | C) * p(3 | H) * p(3 | H) = 0.343

    The probability CHH as explanations of the first three days of data is higher, that's why the probability of first day being hot goes down.


    ii.    The probability that day 2 is hot changes from 0.977 to 0.918.
        Cell K28.

    iii. The graph of p(H) and p(H -> H) on day 1 fell greatly (from approximately 0.9 to 0), while the plot of p(H -> C) and p(C -> C) on day 1 raised slightly. Other part of the graph almost remains unchanged.

    p(H) on day 1 changed from 1.0 to 0. p(H) on day 2 changed from 0.995 to 0.557.

    (b)
    i. p(H) immediately falls to 0 when only 1 ice cream is eaten during the day.

    ii. The graph looks exactly the same as the one before reestimation.

    iii. p(1 | H) = 0.

    The probability p(1 | H) after 10 iterations is defined by sum_{d=1^33}( p_d(H, 1) ) / sum_{d=1^33} ( p_d(H) ).

    Each p_d(H, 1) is equal to p_d(H) if only 1 ice cream is consumed at that day and equal to 0 otherwise.

    p_d(H) = (alpha_d(H) * beta_d(H) / ( alpha_d(H) * beta_d(H) + alpha_d(C) * beta_d(C) )

    alpha_d(H) = ( alpha_{d-1}(C) * p(H | C) + alpha_{d-1}(H) * p(H | H) ) * p(1 | H) if 1 ice cream is consumed at day d.

    p(1 | H) at 10th iteration refers to sum_{d=1^33}( p_d(H, 1) ) / sum_{d=1^33} ( p_d(H) ) of 9th iteration,
    and p(1 | H) at 9th iteration refers to sum_{d=1^33}( p_d(H, 1) ) / sum_{d=1^33} ( p_d(H) ) of 8th iteration, and so on.

    Since we changed p(1 | H) from 0.1 to 0 at the beginning, all alpha_d(H) that relates to eating 1 ice cream at day d in each iteration will be 0. Therefore, p_d(H, 1) will also be 0.

    Thus, p(1 | H) = sum_{d=1^33}( p_d(H, 1) ) / sum_{d=1^33} ( p_d(H) ) = 0 after 10 iterations.


    (c)
        i. The sum of all first word's beta probabilities.
        ii. An H constituent means that particular day with known ice cream consumption ends with a "Hot" tag.
        All the rule we have is
        START -> 2 C
        C     -> 3 H
        H     -> 1 C
        H     -> epsilon

        So,
        p(H -> 1 C) = 0.5
        p(H -> epsilon) = 0.5

        By using the approach on the right hand side, the rules can be more flexible and the total number of rules can possibly reduced. For example, we can write following rules:
        START -> EC C
        EC    -> 1
        EC    -> 2
        EC    -> 3
        ...
4.
    Baseline tagger:
    Tagging accuracy (Viterbi decoding): 92.48% (known: 95.99% novel: 56.07%)
    Perplexity per Viterbi-tagged test word: 1577.499

    Result after improvement:
    Tagging accuracy (Vierbi decoding): 94.13% (known: 96.86% novel: 65.89%)
    Perplexity per Viterbi-tagged test word: 971.540

5.
    Result on ictrain/ictest:
    Tagging accuracy (Viterbi decoding): 90.91% (known: 90.91% novel: 0.00%)
    Perplexity per Viterbi-tagged test word: 3.689
    Tagging accuracy (posterior decoding): 87.88% (known: 87.88% novel: 0.00%)


    Result on entrain/entest:
    Tagging accuracy (Viterbi decoding): 94.13% (known: 96.86% novel: 65.89%)
    Perplexity per Viterbi-tagged test word: 971.540
    Tagging accuracy (posterior decoding): 94.20% (known: 96.90% novel: 66.18%)



6.
    (a) alpha_S(T) probability means the probability from the start state to the state S at time T. The probability for alpha_###(0) that is the start state must be 1 because all the paths must go out from the start state. In the forward process, we process the word stream from the start state to the end state, so we need to set alpha_###(0) to 1.

        beta_S(T) probability means the probability from state S at time T to the end state. The probability for beta_###(n) that is the end state must also be 1 because all the paths must end at the end state. In the backward process, we process the word stream from the end state to the start state, so we need to set beta_###(n) to 1.

    (b)

    (c)

    (d)

    (e)

    (f) If the model is not concave for a maximization problem, then the EM algorithm will possibly get stuck in a local optimal.

    (g) We didn't write diary to keep track of how many ice creams we have eaten everyday. But in our memory, there is a tendency that we ate more ice creams in hot days than in cold days. However, we hadn't eaten any ice cream in some days no matter it was cold or hot. In addition, we didn't eat too many ice creams a day because we think it is not very healthy and we will easily get tired of eating many ice creams due to the sweetness. Thus, for us, weather is not the only factor that will affect the number of ice cream we eat a day. We didn't get sick because we will stop eating ice creams before we get sick.

